# -*- coding: utf-8 -*-
"""randomforestanddecisiontree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HTZhl7Zq9H9pBANzS4fQitN0mYXeqH8p

# **PROBLEM**

 gelen bir hastanın kalp rahatsızlığı varsa,buradaki ilgili özelliklerin analizi ile veriyi modelleyip,uygun eğitim ve test verilerinden başarılar elde etmeye çalışacağım. Bu kodlarda bazı sınıflandırma algoritmaları kullanıp,kalp rahatsızlığı teşhisini doğru değerlendirip,değerlendirmediğimi sonuçlara göre anlayacağım.
"""

#Kütüphaneleri yükle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn import metrics
#from sklearn.cross_validation import KFold   #For K-fold cross validation

#Datayı Oku
df = pd.read_csv("heart-disease.csv") #excelden veris setini okuyup bir data frame içerisine ekledim

df.head() #ilk 5 satırdaki değerleri default olarak görüyorum

df.target.value_counts()

sns.countplot(x = "target", data = df,palette = "hls")
plt.show()

"""Toplamda bu hastalığa sahip 165 hasta var iken,kalp hastalığı ollmayan 138 hasta kaydı bulunmaktadır.Yeşil sütun hasta olan insanlara ait bilgileri tutarken,kırmızı sütun hasta olmayan insanların kayıtlarının görselidir"""

number_of_disease = len(df[df.target == 1])
number_of_healthy = len(df[df.target == 0])
percentage_of_disease = (number_of_disease / (len(df.target)) * 100)
percentage_of_healthy = (number_of_healthy / (len(df.target)) * 100)
print(f"Kalp Hastaliği olan hastaların oranı : ",percentage_of_disease)
print(f"Sağlıklı olan hastaların oranı : ",percentage_of_healthy)

"""Bu küçük hesaplama ile toplam hasta kayıt bilgisi üzerinden sağlıklı veya hasta bulunma yüzdelik değerleri hesaplandı elimdeki örneklem içerisinde bulunan hastaların %54'ü kalp hastası,%45'inde ise kalp hastalığı bulunmamaktadır."""

sns.countplot(x = "sex", data = df, palette = "magma")
plt.xlabel("Gender Values (1 --> Male, 0 --> Female)")
plt.show()

"""Bu grafikte ise cinsiyet öznitelğine bağlı olarak hastalık bulunma değerlerini gözlemledim.Bu veri örnekleminden yola çıkarak "Erkeklerin kadınlara oranla kalp rahatsızlığı olma durumu belirgin bir şekilde fazla bulunuyor" diyebiliriz"""

numberofFemale = len(df[df.sex == 0])
numberofMale = len(df[df.sex == 1])
percentage_of_females = (numberofFemale / (len(df.sex) * 100))
percentage_of_males = (numberofMale / (len(df.sex) * 100))
print(f"Kadın Hasta Oranı: ",percentage_of_females)
print(f"Erkek Hasta Oranı: ",percentage_of_males)

"""Toplamda 303 satır içerisinden yüzde 31'lik dilimde kadın hasta, 68% oranında da erkek hasta olduğunu söylüyor"""

df.groupby("target").mean()

pd.crosstab(df.age,df.target).plot(kind="bar",figsize = (30,15))
plt.title("Yaşlara Göre Kalp Hastalığı Frekans Dağılımı")
plt.xlabel("Yaş")
plt.ylabel("Frekans")
plt.savefig("kalprahatsizligi.png")
plt.show()

pd.crosstab(df.sex,df.target).plot(kind = "bar",figsize=(20,15),color=["#CEF6EC","#FA58D0"])
plt.title("Cinsiyete Göre Kalp Rahatsızlığı Dağılımı Frekansı")
plt.xlabel("Cinsiyet (1 --> Erkek, 0 --> Kadın)")
plt.xticks(rotation = 0)
plt.legend(["Kalp Hastalığı Yok","Kalp Hastalığı Var"])
plt.ylabel("Frekans")
plt.show()

"""Burada da cinsiyete göre hastalığın var olup olmadığını görselleştirdim. Kadınlarda(Xlabeldaki 0 değerine bakıyorum) kalp hastalığı olanlar olmayanlardan oldukça fazla. Erkeklerde (xlabelda 1 olan değere bakıyorum) kalp hastalığı olmayanalrın sayısı olanlardan daha yüksek"""

plt.scatter(x = df.age[df.target == 1], y = df.thalach[(df.target == 1)], c = "pink")
plt.scatter(x = df.age[df.target == 0], y = df.thalach[df.target == 0])
plt.legend(["Hasta","Hasta Değil"])
plt.xlabel("Yaş")
plt.ylabel("Maximum Kalp Atış Hızı")
plt.show()

"""Yaşlara göre kalp atış hızı ile ilşkilendirilmiş 2 boyutlu bir grafite 2 farklı öznitelik ile beraber düşünüldiğinde hasta olma durumunun 30'lu yaşların başından 60'lı yaşlara göre baskın düzeyde oluştuğu görülüyor.Yine de rahatsızlık 70 yaşından uzun hasta kayıtlarında da seyredebiliyor.Hasta olmama durumu ise genellikle 50 ile 70 yaşları arasında daha çok gruplanmış gibi görünüyor"""

pd.crosstab(df.slope,df.target).plot(kind="bar",figsize=(20,15),color=['#DF01D7','#9FF781' ])
plt.title("Kalp Rahatsızlığı Frekans Eğimi")
plt.xlabel("ST Segment'in Pik Değerleri")
plt.xticks(rotation = 0)
plt.ylabel("Frekans")
plt.show()

pd.crosstab(df.fbs,df.target).plot(kind="bar",figsize=(20,15),color=["#0404B4","#F6CED8"])
plt.title("Açlık Kan Şekerine Değerine Göre Kalp Rahatsızlığı Frekansı")
plt.xlabel("FBS - (Açlık Kan Şekeri > 120 mg/dl),(varsa ->1 ,yoksa -> 0)")
plt.xticks(rotation = 0)
plt.legend("Hastalık Yok","Hastalık Var")
plt.ylabel("Hastalık Frekansı Var mı?, Yok mu?")
plt.show()

pd.crosstab(df.cp,df.target).plot(kind="bar",figsize=(15,6),color=['#58FAAC','#FE2E64' ])
plt.title('Göğüsteki Ağrı Tipine Göre Kalp Rahatsızlığı Frekansı')
plt.xlabel('Göğüs Ağrı Tipi')
plt.xticks(rotation = 0)
plt.ylabel('Hastalık Var mı?,Yok mu?')
plt.show()

"""Son 3 bar grafiğinde aslında yapılmak istenen hastalığın farklı kolonlardaki dağılımını analiz etmekti.ST segment değerine göre,açlık kan şekerine göre ve göğüsteki ağrı tipine göre kalp rahatsızlığı var mı,yok mu ve varsa ne kadar oranda bulunuyor bunu anlamaya çalıştım"""

y = df.target.values
x_data = df.drop(["target"], axis = 1)

import pandas as pd

def clean_dataset(df):
    assert isinstance(df, pd.DataFrame), "df needs to be a pd.DataFrame"
    df.dropna(inplace=True)
    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)
    return df[indices_to_keep].astype(np.float64)

"""Veri Normalizasyonu

Veri normalizasyonu formülü X değerleri üzerine inşaa edilmiştir.Ben x_data değişkenimle işlemler yapacağım.X_scaled = (X_data - X_data_min) / (X_data_max - X_data_min) formülü ile verilerimizi normalize edebilirim
"""

x = ( x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1,random_state=0)
x_train = x_train.T
y_train = y_train.T
x_test = x_test.T
y_test = y_test.T

def initialize(dimension):
  weight = np.full((dimension,1),0.01)
  bias = 0.0
  return weight,bias

def sigmoid(z):
  y_head = 1 / (1 + np.exp(-z))
  return y_head

def forwardBackward(weight,bias,x_train,y_train):
    # Forward
    y_head = sigmoid(np.dot(weight.T,x_train) + bias)
    loss = -(y_train*np.log(y_head) + (1-y_train)*np.log(1-y_head))
    cost = np.sum(loss) / x_train.shape[1]
    
    # Backward
    derivative_weight = np.dot(x_train,((y_head-y_train).T))/x_train.shape[1]
    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]
    gradients = {"Derivative Weight" : derivative_weight, "Derivative Bias" : derivative_bias}
    
    return cost,gradients

def update(weight,bias,x_train,y_train,learningRate,iteration) :
    costList = []
    index = []
    
    #for each iteration, update weight and bias values
    for i in range(iteration):
        cost,gradients = forwardBackward(weight,bias,x_train,y_train)
        weight = weight - learningRate * gradients["Derivative Weight"]
        bias = bias - learningRate * gradients["Derivative Bias"]
        
        costList.append(cost)
        index.append(i)

    parameters = {"weight": weight,"bias": bias}
    
    print("iteration:",iteration)
    print("cost:",cost)

    plt.plot(index,costList)
    plt.xlabel("Number of Iteration")
    plt.ylabel("cost")
    plt.show()

    return parameters, gradients


def predict(weight,bias,x_test):
    z = np.dot(weight.T,x_test) + bias
    y_head = sigmoid(z)
    y_prediction = np.zeros((1,x_test.shape[1]))
    for i in range(y_head.shape[1]):
        if y_head[0,i] <= 0.5:
            y_prediction[0,i] = 0
        else:
            y_prediction[0,i] = 1
    return y_prediction

def logistic_regression(x_train,y_train,x_test,y_test,learningRate,iteration):
    dimension = x_train.shape[0]
    weight,bias = initialize(dimension)
    
    parameters, gradients = update(weight,bias,x_train,y_train,learningRate,iteration)

    y_prediction = predict(parameters["weight"],parameters["bias"],x_test)
    
    print("Manuel Test'in Doğruluk Oranı: {:.2f}%".format((100 - np.mean(np.abs(y_prediction - y_test))*100)))

logistic_regression(x_train,y_train,x_test,y_test,1,100)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

accuracies = {}

lr = LogisticRegression()
lr.fit(x_train.T, y_train.T)
acc = lr.score(x_test.T,y_test.T)*100

accuracies['Logistic Regression'] = acc
print("Logistic Regression Doğruluk Değeri {:.2f}%".format(acc))

from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier()
tree.fit(x_train.T , y_train.T)
acc = tree.score(x_test.T, y_test.T) * 100
accuracies["DecisionTree"] = acc
print(f"Karar Ağacı Doğruluk Değeri : ",acc)


from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 1000, random_state = 1)
forest.fit(x_train.T, y_train.T)

acc = forest.score(x_test.T,y_test.T)*100
accuracies['Random Forest'] = acc
print("Random Forest Doğruluk Değeri : {:.2f}%".format(acc))

colors = ["pink","purple","black"]
sns.set_style("dark")
plt.figure(figsize=(20,15))
plt.yticks(np.arange(0,100,10))
plt.ylabel("Doğruluk Yüzdesi")
plt.xlabel("Yöntem Kodlamalar")
sns.barplot(x = list(accuracies.keys()), y=list(accuracies.values()), palette = colors)
plt.show()

""" 3 algoritma arasından en iyi sonuca ulaşan RandomForest oldu.

Decision Tree Doğruluk Değeri : 78.68852459016394

Random Forest Doğruluk Değeri : 88.52%

Logistic Regression Doğruluk Değeri 86.89% 'dir.

Bu eğitilmiş ve test edilmiş doğruluk değerlerinden,bu veri kümesi için en iyi sonuca ulaşan Random Forest algoritmasıdır.Yüksek oranda doğruluk yüzdesi ortaya çıkarmış olduğu için en iyi sonucu verebilir diyebiliriz.
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

y_head_lr = lr.predict(x_test.T)
knn3 = KNeighborsClassifier(n_neighbors = 3)
knn3.fit(x_train.T, y_train.T)
y_head_tree = tree.predict(x_test.T)
y_head_forest = forest.predict(x_test.T)


from sklearn.metrics import confusion_matrix
lr_confm = confusion_matrix(y_test, y_head_lr)
tree_confm = confusion_matrix(y_test, y_head_tree)
forest_confm = confusion_matrix(y_test,y_head_forest)

plt.figure(figsize=(20,15))

plt.title("Confusion Matrix",fontsize = 24)
plt.subplots_adjust(wspace = 0.4, hspace = 0.4)

plt.subplot(2,3,1)
plt.title("Logistic Regression Confusion Matrix")
sns.heatmap(lr_confm,annot=True,cmap="Purples",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,2)
plt.title("Decision Tree Classifier Confusion Matrix")
sns.heatmap(tree_confm,annot=True,cmap="Greens",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,3)
plt.title("Random Forest Confusion Matrix")
sns.heatmap(forest_confm,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.show()

"""Karmaşılık matrisi çıkan 3 kodlamada da

array[0][0] = True Negative

array[0][1] = False Positive

array[1][0] = False Negative

array[1][1] = True Positive

aslında ulaşılmak istenen değerler şu şekilde olmalı.Yani satırlar aslında gerçek hasta olma durumunu 1 veya 0 olarak değerlendirirken,kolonlarda bunları ne kadar tahmin ettiği ile alakalıdır.Bu yüzden True Positive = gerçekten doğru tahmin edilenler True Negative = gerçketen hasta olup,hasta olmadığı teşhis edilenler False Positive = gerçekte hasta olmayıp,hasta olduğu düşünilenler False Negative = gerçekte hasta olmayıp hasta olmadığı tahmin edilen


insanların karmaşılık matrisi bu değerlerden oluşturur.

Random forest algoritmasında ne kadar yüksek doğruluk değerine ulaşsa da aslında gerçe hastaları,hasta olmayarak tahmin eden 14 kaydı var ve bu onun yanlış sınıflandırdığını gösterir.Bu algoritmada decision tree en iyi sınıflandırma yöntemini oluşturuyor denebilir.Ama FP ve FN değerlerini kıyaslarsak bu durum yine Random Forest algoritmasının lehine gerçekleşen bir durum olur.Bu durumda da Random Forest bu veri kümesi için en iyi sınıflandırm sonucunu veren algoritmadır diyebiliriz.
"""